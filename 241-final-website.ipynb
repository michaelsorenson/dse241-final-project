{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_16S = pd.read_csv('NCOG_21_16S_redo2_asv_count_tax.tsv', sep='\\t')\n",
    "data_18Sv4 = pd.read_csv('NCOG_18sV4_asv_count_tax.tsv', sep='\\t')\n",
    "data_18Sv9 = pd.read_csv('NCOG_18sV9_asv_count_tax_S.tsv', sep='\\t')\n",
    "data_meta = pd.read_csv('NCOG_sample_log_DNA_stvx_meta_2014-2020_mod.tsv', sep='\\t')\n",
    "data_meta['sampleid'] = data_meta['sampleid'].apply(lambda x: 'X' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.set_mapbox_access_token('pk.eyJ1IjoibWFzb3JlbnMiLCJhIjoiY2x0ZHhpY2JsMGJwajJ2c2JkY2pwNnZvYyJ9.0BfLEl_lfk7-rs-96XghMQ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surf    772\n",
       "DCM     702\n",
       "515       7\n",
       "170       5\n",
       "Name: sample_type, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta['sample_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample types:\n",
    "### 'Surf' IQR: 10-10 m\n",
    "### 'DCM' IQR: 30-75 m\n",
    "### 515: 515 m\n",
    "### 170: 170 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = data_meta['Sta_ID'].iloc[0]\n",
    "sample_type = 'DCM'\n",
    "dataset = '16S'\n",
    "\n",
    "cols_show_in_sunburst = ['Phylum', 'Class', 'Order']\n",
    "station_data = data_meta[(data_meta['Sta_ID'] == station_id) & (data_meta['sample_type'] == sample_type)]\n",
    "station_samples = station_data['sampleid'].tolist()\n",
    "\n",
    "taxa_col_names = ['Domain', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "\n",
    "# Merge with 16S dataframe to get taxonomy data for the samples\n",
    "asv_cols = pd.Series(data_16S.columns).isin(station_samples).values\n",
    "\n",
    "asv_cols[0] = True\n",
    "station_asvs = pd.concat([data_16S.loc[:,asv_cols], data_16S['silva_Taxon']], axis=1)\n",
    "\n",
    "# Get relative abundances\n",
    "values = station_asvs.drop(['Feature.ID', 'silva_Taxon'], axis=1).sum(axis=1)\n",
    "#values = values / values.sum()\n",
    "\n",
    "# Count occurrences of each taxonomy category\n",
    "taxonomies = station_asvs['silva_Taxon'].str.split('; ', expand=True)\n",
    "taxonomies.columns = taxa_col_names\n",
    "taxonomies = taxonomies.dropna(subset=cols_show_in_sunburst[0]).fillna('___Undetermined')[cols_show_in_sunburst]\n",
    "  \n",
    "# get rid of the silva d__, p__, etc prefixes\n",
    "for col in taxonomies.columns:\n",
    "    taxonomies[col] = taxonomies[col].apply(lambda x: x[3:])\n",
    "\n",
    "# Get relative abundances\n",
    "taxonomies['values'] = values\n",
    "taxonomies = taxonomies[taxonomies['values'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phylum</th>\n",
       "      <th>Class</th>\n",
       "      <th>Order</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>HgCo23</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Marinimicrobia_(SAR406_clade)</td>\n",
       "      <td>Marinimicrobia_(SAR406_clade)</td>\n",
       "      <td>Marinimicrobia_(SAR406_clade)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Puniceispirillales</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>SAR86_clade</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Thermoplasmatota</td>\n",
       "      <td>Thermoplasmata</td>\n",
       "      <td>Marine_Group_II</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28815</th>\n",
       "      <td>Marinimicrobia_(SAR406_clade)</td>\n",
       "      <td>Marinimicrobia_(SAR406_clade)</td>\n",
       "      <td>Marinimicrobia_(SAR406_clade)</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>Verrucomicrobiota</td>\n",
       "      <td>Verrucomicrobiae</td>\n",
       "      <td>Opitutales</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28834</th>\n",
       "      <td>Bacteroidota</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28838</th>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>SAR11_clade</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28839</th>\n",
       "      <td>Cyanobacteria</td>\n",
       "      <td>Cyanobacteriia</td>\n",
       "      <td>Chloroplast</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1305 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Phylum                          Class  \\\n",
       "16                    Proteobacteria            Gammaproteobacteria   \n",
       "54     Marinimicrobia_(SAR406_clade)  Marinimicrobia_(SAR406_clade)   \n",
       "100                   Proteobacteria            Alphaproteobacteria   \n",
       "121                   Proteobacteria            Gammaproteobacteria   \n",
       "175                 Thermoplasmatota                 Thermoplasmata   \n",
       "...                              ...                            ...   \n",
       "28815  Marinimicrobia_(SAR406_clade)  Marinimicrobia_(SAR406_clade)   \n",
       "28830              Verrucomicrobiota               Verrucomicrobiae   \n",
       "28834                   Bacteroidota                    Bacteroidia   \n",
       "28838                 Proteobacteria            Alphaproteobacteria   \n",
       "28839                  Cyanobacteria                 Cyanobacteriia   \n",
       "\n",
       "                               Order  values  \n",
       "16                            HgCo23      66  \n",
       "54     Marinimicrobia_(SAR406_clade)       9  \n",
       "100               Puniceispirillales      78  \n",
       "121                      SAR86_clade      43  \n",
       "175                  Marine_Group_II     841  \n",
       "...                              ...     ...  \n",
       "28815  Marinimicrobia_(SAR406_clade)     596  \n",
       "28830                     Opitutales       3  \n",
       "28834               Flavobacteriales      27  \n",
       "28838                    SAR11_clade      37  \n",
       "28839                    Chloroplast     982  \n",
       "\n",
       "[1305 rows x 4 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-258-8ded30cd9efa>, line 182)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-258-8ded30cd9efa>\"\u001b[1;36m, line \u001b[1;32m182\u001b[0m\n\u001b[1;33m    sunburst_figs[station_id][sample_type][dataset] =\u001b[0m\n\u001b[1;37m                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "data_16S = pd.read_csv('NCOG_21_16S_redo2_asv_count_tax.tsv', sep='\\t')\n",
    "data_18Sv4 = pd.read_csv('NCOG_18sV4_asv_count_tax.tsv', sep='\\t')\n",
    "data_18Sv9 = pd.read_csv('NCOG_18sV9_asv_count_tax_S.tsv', sep='\\t')\n",
    "data_meta = pd.read_csv('NCOG_sample_log_DNA_stvx_meta_2014-2020_mod.tsv', sep='\\t')\n",
    "data_meta['sampleid'] = data_meta['sampleid'].apply(lambda x: 'X' + x)\n",
    "\n",
    "cal_coast_center = dict(\n",
    "    lat=np.mean([min(data_meta['Lat_Dec']), max(data_meta['Lat_Dec'])]),\n",
    "    lon=np.mean([min(data_meta['Lon_Dec']), max(data_meta['Lon_Dec'])])\n",
    ")\n",
    "env_var_cols = ['T_degC', 'Salnty', 'O2ml_L', 'PO4ug', 'SiO3ug', 'NO3ug', 'NH3ug', 'ChlorA', 'IntC14', 'NCDepth']\n",
    "sample_type_vals = data_meta['sample_type'].dropna().unique()\n",
    "\n",
    "# dash app\n",
    "# app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "\n",
    "# app.layout = dbc.Container([\n",
    "#     html.H1(\"CO2 Emissions Dashboard\", className=\"mt-4 mb-4\"),\n",
    "#     dbc.Row([\n",
    "#         dbc.Col([\n",
    "#             html.Div([\n",
    "#                 html.Label(\"Select Sector\"),\n",
    "#                 dcc.Dropdown(\n",
    "#                     id='sector-dropdown',\n",
    "#                     options=sector_options,\n",
    "#                     value='Electric Power'\n",
    "#                 ),\n",
    "#                 html.Label(\"Select Year\"),\n",
    "#                 dcc.Slider(\n",
    "#                     id='year-slider',\n",
    "#                     min=co2_data['Year'].min(),\n",
    "#                     max=co2_data['Year'].max(),\n",
    "#                     value=co2_data['Year'].max(),\n",
    "#                     marks={str(year): str(year) for year in co2_data['Year'].unique()},\n",
    "#                     step=None\n",
    "#                 ),\n",
    "#             ], className=\"mb-4\")\n",
    "#         ], width=3),\n",
    "#         dbc.Col([\n",
    "#             dcc.Graph(id='co2-heatmap')\n",
    "#         ], width=6),\n",
    "#         dbc.Col([\n",
    "#             dcc.Graph(id='state-lineplot')\n",
    "#         ], width=3)\n",
    "#     ])\n",
    "# ], fluid=True)\n",
    "MYSTAID = None\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.H3('Sample Type:'),\n",
    "        dcc.Dropdown(sample_type_vals, sample_type_vals[0], id='sample-type-dropdown'),\n",
    "        html.H3('Environmental Variable (Color):'),\n",
    "        dcc.Dropdown(env_var_cols, 'NCDepth', id='env-var-dropdown')\n",
    "    ]),\n",
    "    html.Div([\n",
    "        dcc.Graph(id='map-graph')\n",
    "    ]),\n",
    "    html.Div([\n",
    "        html.H3('Dataset:'),\n",
    "        dcc.Dropdown(['16S', '18Sv4', '18Sv9'], '16S', id='dataset-dropdown')\n",
    "    ]),\n",
    "    html.Div([\n",
    "        dcc.Graph(id='sunburst-graph')\n",
    "    ]),\n",
    "])\n",
    "\n",
    "# precompute map figures for different sample types\n",
    "map_figs = {sample_type: {} for sample_type in data_meta['sample_type'].unique()}\n",
    "for sample_type in data_meta['sample_type'].unique():\n",
    "    for env_var in env_var_cols:\n",
    "        meta_subset = data_meta[data_meta['sample_type'] == sample_type]\n",
    "        num_samples = meta_subset.groupby('Sta_ID')['sample_num'].count()\n",
    "        meta_subset = meta_subset.groupby('Sta_ID').mean().reset_index()\n",
    "        meta_subset['num_samples'] = num_samples\n",
    "        hover_names = meta_subset['Sta_ID'].apply(lambda x: '<b>Station: </b>' + x)\n",
    "        subset_fig = px.scatter_mapbox(meta_subset, lat='Lat_Dec', lon='Lon_Dec', center=cal_coast_center,\n",
    "                                       color=env_var, hover_name=hover_names, #size=\"num_samples\",\n",
    "                                       color_continuous_scale='viridis', size_max=15, zoom=4.5, mapbox_style='outdoors',\n",
    "                                       width=600, height=700, custom_data='Sta_ID')\n",
    "        map_figs[sample_type][env_var] = subset_fig\n",
    "\n",
    "# empty sunburst figure if the station has no data of the selected sample type\n",
    "empty_sunburst_data = {'Phylum': [], 'Class': [], 'Order': []}\n",
    "for parent in ['Undetermined_1', 'Undetermined_2', 'Undetermined_3']:\n",
    "    for child1 in ['Undetermined_1', 'Undetermined_2', 'Undetermined_3']:\n",
    "        for child2 in ['Undetermined_1', 'Undetermined_2', 'Undetermined_3']:\n",
    "            empty_sunburst_data['Phylum'].append(parent)\n",
    "            empty_sunburst_data['Class'].append(child1)\n",
    "            empty_sunburst_data['Order'].append(child2)\n",
    "empty_sunburst_fig = px.sunburst(empty_sunburst_data, path=['Phylum', 'Class', 'Order'])\n",
    "\n",
    "# precompute sunburst figures\n",
    "sunburst_figs = {station_id: {} for station_id in data_meta['Sta_ID'].unique()}\n",
    "for station_id in data_meta['Sta_ID'].unique():\n",
    "    for sample_type in data_meta['sample_type'].unique():\n",
    "        sunburst_figs[station_id][sample_type] = {}\n",
    "        for dataset in ['16S', '18Sv4', '18Sv9']:\n",
    "            cols_show_in_sunburst = ['Phylum', 'Class', 'Order']\n",
    "            station_data = data_meta[(data_meta['Sta_ID'] == station_id) & (data_meta['sample_type'] == sample_type)]\n",
    "            station_samples = station_data['sampleid'].tolist()\n",
    "            if dataset =='16S':\n",
    "                taxa_col_names = ['Domain', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "\n",
    "                # Merge with 16S dataframe to get taxonomy data for the samples\n",
    "                asv_cols = pd.Series(data_16S.columns).isin(station_samples).values\n",
    "                asv_cols[0] = True\n",
    "                station_asvs = pd.concat([data_16S.loc[:,asv_cols], data_16S['silva_Taxon']], axis=1)\n",
    "\n",
    "                # Get relative abundances\n",
    "                values = station_asvs.drop(['Feature.ID', 'silva_Taxon'], axis=1).sum(axis=0)\n",
    "                #values = values / values.sum()\n",
    "\n",
    "                # Count occurrences of each taxonomy category\n",
    "                taxonomies = station_asvs['silva_Taxon'].str.split('; ', expand=True)\n",
    "                taxonomies.columns = taxa_col_names\n",
    "                taxonomies = taxonomies.dropna(subset=cols_show_in_sunburst[0]).fillna('___Undetermined')[cols_show_in_sunburst]\n",
    "\n",
    "                # get rid of the silva d__, p__, etc prefixes\n",
    "                for col in taxonomies.columns:\n",
    "                    taxonomies[col] = taxonomies[col].apply(lambda x: x[3:])\n",
    "\n",
    "                # Get relative abundances\n",
    "                taxonomies['values'] = values\n",
    "\n",
    "                # set title of plot\n",
    "                title = '16S Silva Taxonomy, Station \"' + station_id + '\"'\n",
    "            elif dropdown_dataset == '18Sv4':\n",
    "                taxa_col_names = ['Kingdom', 'Domain', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "                # Merge with 18Sv4 dataframe to get taxonomy data for the samples\n",
    "                asv_cols = pd.Series(data_18Sv4.columns).isin(station_samples).values\n",
    "                asv_cols[0] = True\n",
    "                station_asvs = pd.concat([data_18Sv4.loc[:,asv_cols], data_18Sv4['pr2_Taxon']], axis=1)\n",
    "\n",
    "                # Get relative abundances\n",
    "                values = station_asvs.drop(['Feature.ID', 'pr2_Taxon'], axis=1).sum(axis=0)\n",
    "                #values = values / values.sum()\n",
    "\n",
    "                # Count occurrences of each taxonomy category\n",
    "                taxonomies = station_asvs['pr2_Taxon'].str.split(';', expand=True)\n",
    "                taxonomies = taxonomies.iloc[:, :8]\n",
    "                taxonomies.columns = taxa_col_names\n",
    "                taxonomies = taxonomies.dropna(subset='Phylum').fillna('Undetermined')[cols_show_in_sunburst]\n",
    "\n",
    "                # Add relative abundances\n",
    "                taxonomies['values'] = values\n",
    "\n",
    "                # set title of plot\n",
    "                title = '18S v4 PR2 Taxonomy, Station \"' + station_id + '\"'\n",
    "\n",
    "            elif dropdown_dataset == '18Sv9':\n",
    "                taxa_col_names = ['Kingdom', 'Domain', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "\n",
    "                # Merge with 18Sv9 dataframe to get taxonomy data for the samples\n",
    "                asv_cols = pd.Series(data_18Sv9.columns).isin(station_samples).values\n",
    "                asv_cols[0] = True\n",
    "                station_asvs = pd.concat([data_18Sv9.loc[:,asv_cols], data_18Sv9['pr2_Taxon']], axis=1)\n",
    "\n",
    "                # Get relative abundances\n",
    "                values = station_asvs.drop(['Feature.ID', 'pr2_Taxon'], axis=1).sum(axis=0)\n",
    "                #values = values / values.sum()\n",
    "\n",
    "                # Count occurrences of each taxonomy category\n",
    "                taxonomies = station_asvs['pr2_Taxon'].str.split(';', expand=True)\n",
    "                taxonomies = taxonomies.iloc[:, :8]\n",
    "                taxonomies.columns = taxa_col_names\n",
    "                taxonomies = taxonomies.dropna(subset='Phylum').fillna('Undetermined')[cols_show_in_sunburst]\n",
    "\n",
    "                # Add relative abundances\n",
    "                taxonomies['values'] = values\n",
    "\n",
    "                # set title of plot\n",
    "                title = '18S v9 PR2 Taxonomy, Station \"' + station_id + '\"'\n",
    "                \n",
    "            fig = px.sunburst(taxonomies, path=['Phylum', 'Class', 'Order'], values='values', title=title)\n",
    "            sunburst_figs[station_id][sample_type][dataset] = fig\n",
    "# Map graph dropdown callback\n",
    "@app.callback(\n",
    "    Output('map-graph', 'figure'),\n",
    "    [Input('sample-type-dropdown', 'value'),\n",
    "     Input('env-var-dropdown', 'value')]\n",
    ")\n",
    "def update_map(dropdown_sample_type, dropdown_env_var):\n",
    "    return map_figs[dropdown_sample_type][dropdown_env_var]\n",
    "\n",
    "# Map graph click data callback\n",
    "@app.callback(\n",
    "    Output('sunburst-graph', 'figure'),\n",
    "    [Input('sample-type-dropdown', 'value'),\n",
    "     Input('map-graph', 'clickData'),\n",
    "     Input('dataset-dropdown', 'value')]\n",
    ")\n",
    "def update_sunburst(dropdown_sample_type, click_data, dropdown_dataset):\n",
    "    if click_data is None:\n",
    "        station_id = data_meta['Sta_ID'].iloc[0]\n",
    "    # Get station ID from hover data\n",
    "    else:\n",
    "        if 'customdata' not in click_data['points'][0]:\n",
    "            station_id = station_id = data_meta['Sta_ID'].iloc[0]\n",
    "        else:\n",
    "            station_id = click_data['points'][0]['customdata'][0]\n",
    "    testing = (dropdown_sample_type, click_data, dropdown_dataset)\n",
    "    cols_show_in_sunburst = ['Phylum', 'Class', 'Order']\n",
    "    station_data = data_meta[(data_meta['Sta_ID'] == station_id) & (data_meta['sample_type'] == dropdown_sample_type)]\n",
    "    station_samples = station_data['sampleid'].tolist()\n",
    "    if dropdown_dataset == '16S':\n",
    "        taxa_col_names = ['Domain', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "\n",
    "        # Merge with 16S dataframe to get taxonomy data for the samples\n",
    "        asv_cols = pd.Series(data_16S.columns).isin(station_samples).values\n",
    "        asv_cols[0] = True\n",
    "        station_asvs = pd.concat([data_16S.loc[:,asv_cols], data_16S['silva_Taxon']], axis=1)\n",
    "\n",
    "        # Get relative abundances\n",
    "        values = station_asvs.drop(['Feature.ID', 'silva_Taxon'], axis=1).sum(axis=0)\n",
    "        #values = values / values.sum()\n",
    "\n",
    "        # Count occurrences of each taxonomy category\n",
    "        taxonomies = station_asvs['silva_Taxon'].str.split('; ', expand=True)\n",
    "        taxonomies.columns = taxa_col_names\n",
    "        taxonomies = taxonomies.dropna(subset=cols_show_in_sunburst[0]).fillna('___Undetermined')[cols_show_in_sunburst]\n",
    "\n",
    "        # get rid of the silva d__, p__, etc prefixes\n",
    "        for col in taxonomies.columns:\n",
    "            taxonomies[col] = taxonomies[col].apply(lambda x: x[3:])\n",
    "\n",
    "        # Get relative abundances\n",
    "        taxonomies['values'] = values\n",
    "\n",
    "        # set title of plot\n",
    "        title = '16S Silva Taxonomy, Station \"' + station_id + '\"'\n",
    "    elif dropdown_dataset == '18Sv4':\n",
    "        taxa_col_names = ['Kingdom', 'Domain', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "        # Merge with 18Sv4 dataframe to get taxonomy data for the samples\n",
    "        asv_cols = pd.Series(data_18Sv4.columns).isin(station_samples).values\n",
    "        asv_cols[0] = True\n",
    "        station_asvs = pd.concat([data_18Sv4.loc[:,asv_cols], data_18Sv4['pr2_Taxon']], axis=1)\n",
    "        \n",
    "        # Get relative abundances\n",
    "        values = station_asvs.drop(['Feature.ID', 'pr2_Taxon'], axis=1).sum(axis=0)\n",
    "        #values = values / values.sum()\n",
    "        \n",
    "        # Count occurrences of each taxonomy category\n",
    "        taxonomies = station_asvs['pr2_Taxon'].str.split(';', expand=True)\n",
    "        taxonomies = taxonomies.iloc[:, :8]\n",
    "        taxonomies.columns = taxa_col_names\n",
    "        taxonomies = taxonomies.dropna(subset='Phylum').fillna('Undetermined')[cols_show_in_sunburst]\n",
    "        \n",
    "        # Add relative abundances\n",
    "        taxonomies['values'] = values\n",
    "        \n",
    "        # set title of plot\n",
    "        title = '18S v4 PR2 Taxonomy, Station \"' + station_id + '\"'\n",
    "        \n",
    "    elif dropdown_dataset == '18Sv9':\n",
    "        taxa_col_names = ['Kingdom', 'Domain', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "        \n",
    "        # Merge with 18Sv9 dataframe to get taxonomy data for the samples\n",
    "        asv_cols = pd.Series(data_18Sv9.columns).isin(station_samples).values\n",
    "        asv_cols[0] = True\n",
    "        station_asvs = pd.concat([data_18Sv9.loc[:,asv_cols], data_18Sv9['pr2_Taxon']], axis=1)\n",
    "        \n",
    "        # Get relative abundances\n",
    "        values = station_asvs.drop(['Feature.ID', 'pr2_Taxon'], axis=1).sum(axis=0)\n",
    "        #values = values / values.sum()\n",
    "        \n",
    "        # Count occurrences of each taxonomy category\n",
    "        taxonomies = station_asvs['pr2_Taxon'].str.split(';', expand=True)\n",
    "        taxonomies = taxonomies.iloc[:, :8]\n",
    "        taxonomies.columns = taxa_col_names\n",
    "        taxonomies = taxonomies.dropna(subset='Phylum').fillna('Undetermined')[cols_show_in_sunburst]\n",
    "        \n",
    "        # Add relative abundances\n",
    "        taxonomies['values'] = values\n",
    "        \n",
    "        # set title of plot\n",
    "        title = '18S v9 PR2 Taxonomy, Station \"' + station_id + '\"'\n",
    "\n",
    "    fig = px.sunburst(taxonomies, path=['Phylum', 'Class', 'Order'], values='values', title=title)\n",
    "    return fig\n",
    "\n",
    "app.run_server(debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DCM',\n",
       " {'points': [{'curveNumber': 0,\n",
       "    'pointNumber': 81,\n",
       "    'pointIndex': 81,\n",
       "    'lon': -122.919264,\n",
       "    'lat': 30.1766,\n",
       "    'cluster.color': 109.27527107600001,\n",
       "    'hovertext': '<b>Station: </b>093.3 110.0',\n",
       "    'marker.color': 109.27527107600001,\n",
       "    'bbox': {'x0': 250.58165279109159,\n",
       "     'x1': 252.58165279109159,\n",
       "     'y0': 664.649583672675,\n",
       "     'y1': 666.649583672675},\n",
       "    'customdata': ['093.3 110.0']}]},\n",
       " '16S')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c57538dfa3b0>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-c57538dfa3b0>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    data_18Sv9 =\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import json\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "\n",
    "px.set_mapbox_access_token('pk.eyJ1IjoibWFzb3JlbnMiLCJhIjoiY2x0ZHhpY2JsMGJwajJ2c2JkY2pwNnZvYyJ9.0BfLEl_lfk7-rs-96XghMQ')\n",
    "\n",
    "# Step 2: Load the dataset, population data, and GeoJSON file\n",
    "data_16S = pd.read_csv('NCOG_21_16S_redo2_asv_count_tax.tsv', sep='\\t')\n",
    "data_18Sv4 = pd.read_csv('NCOG_18sV4_asv_count_tax.tsv', sep='\\t')\n",
    "data_18Sv9 = pd.read_csv('NCOG_18sV9_asv_count_tax_S.tsv', sep='\\t')\n",
    "data_meta = pd.read_csv('NCOG_sample_log_DNA_stvx_meta_2014-2020_mod.tsv', sep='\\t')\n",
    "\n",
    "# Create map graph\n",
    "# Create scattergeo trace for stations\n",
    "trace = go.Scattergeo(\n",
    "    lon=meta['Lon_Dec'],\n",
    "    lat=meta['Lat_Dec'],\n",
    "    text=meta['Sta_ID'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        color='rgb(255, 0, 0)',\n",
    "        line=dict(\n",
    "            width=3,\n",
    "            color='rgba(68, 68, 68, 0)'\n",
    "        )\n",
    "    ),\n",
    "    hoverinfo='text'\n",
    ")\n",
    "\n",
    "    # Create layout for the map\n",
    "    layout = go.Layout(\n",
    "        title='Ocean Off the California Coast',\n",
    "        geo=dict(\n",
    "            scope='usa',\n",
    "            projection=dict(type='albers usa'),\n",
    "            showland=True,\n",
    "            landcolor='rgb(217, 217, 217)',\n",
    "            subunitwidth=1,\n",
    "            countrywidth=1,\n",
    "            subunitcolor='rgb(255,255,255)',\n",
    "            countrycolor='rgb(255,255,255)'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the map figure\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "    return fig\n",
    "# Step 3: Create a Dash application\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Step 4: Create dropdown menu for sector selection\n",
    "sector_options = [{'label': sector, 'value': sector} for sector in co2_data['Sector'].unique()]\n",
    "\n",
    "# Step 5: Define layout\n",
    "app.layout = dbc.Container([\n",
    "    html.H1(\"NCOG Data\", className=\"mt-4 mb-4\"),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Div([\n",
    "                html.Label(\"Select Sector\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='sector-dropdown',\n",
    "                    options=sector_options,\n",
    "                    value='Electric Power'\n",
    "                ),\n",
    "                html.Label(\"Select Year\"),\n",
    "                dcc.Slider(\n",
    "                    id='year-slider',\n",
    "                    min=co2_data['Year'].min(),\n",
    "                    max=co2_data['Year'].max(),\n",
    "                    value=co2_data['Year'].max(),\n",
    "                    marks={str(year): str(year) for year in co2_data['Year'].unique()},\n",
    "                    step=None\n",
    "                ),\n",
    "            ], className=\"mb-4\")\n",
    "        ], width=3),\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='co2-heatmap')\n",
    "        ], width=6),\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='state-lineplot')\n",
    "        ], width=3)\n",
    "    ])\n",
    "], fluid=True)\n",
    "\n",
    "# Step 6: Define callbacks to update the heatmap and line plot based on user selection\n",
    "@app.callback(\n",
    "    [Output('co2-heatmap', 'figure'),\n",
    "     Output('state-lineplot', 'figure')],\n",
    "    [Input('sector-dropdown', 'value'),\n",
    "     Input('year-slider', 'value'),\n",
    "     Input('co2-heatmap', 'hoverData')]\n",
    ")\n",
    "def update_visualizations(selected_sector, selected_year, hoverData):\n",
    "    # California coast NCOG sample map\n",
    "    def create_map_graph():\n",
    "    # Create scattergeo trace for stations\n",
    "    trace = go.Scattergeo(\n",
    "        lon=meta['Lon_Dec'],\n",
    "        lat=meta['Lat_Dec'],\n",
    "        text=meta['Sta_ID'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color='rgb(255, 0, 0)',\n",
    "            line=dict(\n",
    "                width=3,\n",
    "                color='rgba(68, 68, 68, 0)'\n",
    "            )\n",
    "        ),\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "\n",
    "    # Create layout for the map\n",
    "    layout = go.Layout(\n",
    "        title='Ocean Off the California Coast',\n",
    "        geo=dict(\n",
    "            scope='usa',\n",
    "            projection=dict(type='albers usa'),\n",
    "            showland=True,\n",
    "            landcolor='rgb(217, 217, 217)',\n",
    "            subunitwidth=1,\n",
    "            countrywidth=1,\n",
    "            subunitcolor='rgb(255,255,255)',\n",
    "            countrycolor='rgb(255,255,255)'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the map figure\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "    return fig\n",
    "    # Update line plot\n",
    "    if hoverData is not None:\n",
    "        state_name = hoverData['points'][0]['location']\n",
    "        state_data = filtered_data[filtered_data['State'] == state_name]\n",
    "        fig_lineplot = px.line(state_data, x='Year', y='Value', title=f'CO2 Emissions over Time for {state_name} - {selected_sector}')\n",
    "        # Calculate average emissions over time\n",
    "        avg_emissions = filtered_data.groupby('Year')['Value'].mean().reset_index()\n",
    "        fig_lineplot.add_scatter(x=avg_emissions['Year'], y=avg_emissions['Value'], mode='lines', name='Average All States', line=dict(color='black'))\n",
    "\n",
    "        # Create scatter trace using Plotly Express\n",
    "        scatter_trace = px.scatter(state_data, x='Year', y='Value', color='Sector', title=f'Sector-wise CO2 Emissions over Time for {state_name}')\n",
    "        scatter_trace = scatter_trace.update_traces(marker=dict(size=8))\n",
    "\n",
    "        # Convert Plotly Express figure to Plotly graph object\n",
    "        scatter_trace_json = scatter_trace.to_plotly_json()\n",
    "\n",
    "        # Append scatter trace to the line plot\n",
    "        for trace in scatter_trace_json['data']:\n",
    "            fig_lineplot.add_trace(go.Scatter(trace))\n",
    "\n",
    "    else:\n",
    "        fig_lineplot = px.line(title='Hover over a state on the heatmap to see its emissions over time')\n",
    "\n",
    "    return fig_heatmap, fig_lineplot\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
